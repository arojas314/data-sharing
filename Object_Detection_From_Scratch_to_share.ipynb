{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsjDCIat6_UK"
   },
   "source": [
    "# Image Classification and Object Localization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpiJj8ym0v0-"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AoilhmYe1b5t",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 18:37:41.971595: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-05 18:37:41.971651: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-05 18:37:41.971676: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-05 18:37:41.978688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import os, re, time, json\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "os.environ['KMP_DUPLICATION_LIB_OK']=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmoFKEd98MP3"
   },
   "source": [
    "# Visualization Utilities\n",
    "\n",
    "These functions are used to draw bounding boxes around the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tBjj1Fg-i_lc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 18:37:45.797903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:37:45.813538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:37:45.813581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USx9tRBF8hWy"
   },
   "source": [
    "These utilities are used to visualize the data and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cCpkS9C_H7Tl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1 # Gobal batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "Read images into an array of (N, H, W, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "# Read training and testing dataset\n",
    "def get_images_labels_bboxes(fdir):\n",
    "    \"\"\"\n",
    "    Returns: (training_images, training_labels, training_bboxs\n",
    "    \"\"\"\n",
    "    \n",
    "    # read in training imagery as (N x H x W x D)\n",
    "    # fdir = r\"E:\\projects\\burner-airfield\\data\\processed\\gt\\train\"\n",
    "    img_fps = glob.glob(os.path.join(fdir, \"*.tif\"))\n",
    "    # loop through each img, get matching label file, add to list and combine all imgs into array of (N  H x W x D)\n",
    "    img_list = []\n",
    "    labels_coords = [] # list of tuples (xmin, ymin, xmax, ymax)\n",
    "    labels_class = [] # list of labels classes (in same order as labels_coords)\n",
    "    for img_fp in img_fps:\n",
    "        label_fp = img_fp.replace(\".tif\",\".json\")\n",
    "        # Get image as array\n",
    "        img_np = np.array(Image.open(img_fp).convert(\"RGB\"))\n",
    "        img_list.append(img_np)\n",
    "        with open(label_fp) as f:\n",
    "            img_label = json.load(f)\n",
    "            for label in img_label['shapes']:\n",
    "                # get bbox coords (label[\"points\"][0] is upper left coords, label[\"points\"][1] is lower right coords)\n",
    "                xmin,ymin = label['points'][0][0], label[\"points\"][0][1]\n",
    "                xmax,ymax = label['points'][1][0], label[\"points\"][1][1]\n",
    "                labels_coords.append([xmin,ymin,xmax,ymax])\n",
    "                if label['label']==\"GCP_RED\":\n",
    "                    lbl = 1\n",
    "                elif label['label']==\"GCP\":\n",
    "                    lbl = 2\n",
    "                labels_class.append(lbl)\n",
    "    # img_stack = np.stack(img_list, axis=0)\n",
    "    img_stack = np.array(img_list)\n",
    "    \n",
    "    return (img_stack, np.array(labels_class), np.array(labels_coords)) # is rehsape necessary for labels_class?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels, training_bboxes) = get_images_labels_bboxes(\"./train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(test_images, test_labels, test_bboxes) = get_images_labels_bboxes(\"./test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 424, 424, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE8dgyPC1_6m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ4tjPKvL2eh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8nHWWkS_eeZ"
   },
   "source": [
    "## Define the Network\n",
    "\n",
    "Here, you'll define your custom CNN.\n",
    "- `feature_extractor`: these convolutional layers extract the features of the image.\n",
    "- `classifier`:  This defines the output layer that predicts among 2 categories (GCP_RED and GCP (or 1 and 2))\n",
    "- `bounding_box_regression`: This defines the output layer that predicts 4 numeric values, which define the coordinates of the bounding box (xmin, ymin, xmax, ymax)\n",
    "- `final_model`: This combines the layers for feature extraction, classification and bounding box prediction.  \n",
    "  - This is a branching model, because the model splits to produce two kinds of output (a category and set of numbers).  \n",
    "- `define_and_compile_model`: choose the optimizer and metrics, then compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "56y8UNFQIVwj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 424, 424, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 422, 422, 16)         448       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 211, 211, 16)         0         ['conv2d[0][0]']              \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 209, 209, 32)         4640      ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, 104, 104, 32)         0         ['conv2d_1[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 102, 102, 64)         18496     ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (Avera  (None, 51, 51, 64)           0         ['conv2d_2[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 166464)               0         ['average_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  2130752   ['flatten[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " classification (Dense)      (None, 2)                    258       ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " bounding_box (Dense)        (None, 4)                    516       ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21331878 (81.37 MB)\n",
      "Trainable params: 21331878 (81.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 18:38:16.716963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:38:16.717056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:38:16.717091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:38:17.583107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:38:17.583163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:38:17.583172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-05 18:38:17.583219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-05 18:38:17.583242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4577 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Feature extractor is the CNN that is made up of convolution and pooling layers.\n",
    "'''\n",
    "def feature_extractor(inputs):\n",
    "    x = tf.keras.layers.Conv2D(16, activation='relu', kernel_size=3, input_shape=(424, 424, 3))(inputs)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32,kernel_size=3,activation='relu')(x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64,kernel_size=3,activation='relu')(x)\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "'''\n",
    "dense_layers adds a flatten and dense layer.\n",
    "This will follow the feature extraction layers\n",
    "'''\n",
    "def dense_layers(inputs):\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "'''\n",
    "Classifier defines the classification output.\n",
    "This has a set of fully connected layers and a softmax layer.\n",
    "'''\n",
    "def classifier(inputs):\n",
    "    classification_output = tf.keras.layers.Dense(2, activation='softmax', name = 'classification')(inputs)\n",
    "    # classification_output = tf.keras.layers.Dense(1, activation='softmax', name = 'classification')(inputs) # works but so should above\n",
    "    return classification_output\n",
    "\n",
    "\n",
    "'''\n",
    "This function defines the regression output for bounding box prediction.\n",
    "Note that we have four outputs corresponding to (xmin, ymin, xmax, ymax)\n",
    "'''\n",
    "def bounding_box_regression(inputs):\n",
    "    bounding_box_regression_output = tf.keras.layers.Dense(units = '4', name = 'bounding_box')(inputs)\n",
    "    return bounding_box_regression_output\n",
    "\n",
    "\n",
    "def final_model(inputs):\n",
    "    feature_cnn = feature_extractor(inputs)\n",
    "    dense_output = dense_layers(feature_cnn)\n",
    "\n",
    "    '''\n",
    "    The model branches here.\n",
    "    The dense layer's output gets fed into two branches:\n",
    "    classification_output and bounding_box_output\n",
    "    '''\n",
    "    classification_output = classifier(dense_output)\n",
    "    bounding_box_output = bounding_box_regression(dense_output)\n",
    "\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = [classification_output, bounding_box_output])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def define_and_compile_model(inputs):\n",
    "    model = final_model(inputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = {'classification' : 'sparse_categorical_crossentropy',\n",
    "                          'bounding_box' : 'mse'\n",
    "                         },\n",
    "                  metrics = {'classification' : 'accuracy',\n",
    "                             'bounding_box' : 'mse'\n",
    "                            })\n",
    "    # Returns full and compiled model\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(424, 424, 3))\n",
    "# inputs = tf.keras.layers.Input(shape=(None, 424, 424, 3))\n",
    "model = define_and_compile_model(inputs)\n",
    "\n",
    "# print model layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuhDh8ao8VyB"
   },
   "source": [
    "### Train and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine train bbox and train labels into dictionary\n",
    "trainTargets = {\n",
    "    \"classification\": training_labels,\n",
    "    \"bounding_box\": training_bboxes\n",
    "}\n",
    "\n",
    "testTargets = {\n",
    "    \"classification\": test_labels,\n",
    "    \"bounding_box\": test_bboxes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TTwH_P-ZJ_xx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 18:38:32.404212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-05 18:38:51.942315: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-05 18:38:53.149187: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-05 18:38:53.474278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1328e36e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-05 18:38:53.474331: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "2023-11-05 18:38:53.478764: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-05 18:38:53.585642: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 36s 46ms/step - loss: nan - classification_loss: nan - bounding_box_loss: nan - classification_accuracy: 0.0556 - bounding_box_mse: nan - val_loss: nan - val_classification_loss: nan - val_bounding_box_loss: nan - val_classification_accuracy: 0.0000e+00 - val_bounding_box_mse: nan\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 0s 19ms/step - loss: nan - classification_loss: nan - bounding_box_loss: nan - classification_accuracy: 0.0000e+00 - bounding_box_mse: nan - val_loss: nan - val_classification_loss: nan - val_bounding_box_loss: nan - val_classification_accuracy: 0.0000e+00 - val_bounding_box_mse: nan\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 0s 20ms/step - loss: nan - classification_loss: nan - bounding_box_loss: nan - classification_accuracy: 0.0000e+00 - bounding_box_mse: nan - val_loss: nan - val_classification_loss: nan - val_bounding_box_loss: nan - val_classification_accuracy: 0.0000e+00 - val_bounding_box_mse: nan\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 0s 20ms/step - loss: nan - classification_loss: nan - bounding_box_loss: nan - classification_accuracy: 0.0000e+00 - bounding_box_mse: nan - val_loss: nan - val_classification_loss: nan - val_bounding_box_loss: nan - val_classification_accuracy: 0.0000e+00 - val_bounding_box_mse: nan\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 0s 20ms/step - loss: nan - classification_loss: nan - bounding_box_loss: nan - classification_accuracy: 0.0000e+00 - bounding_box_mse: nan - val_loss: nan - val_classification_loss: nan - val_bounding_box_loss: nan - val_classification_accuracy: 0.0000e+00 - val_bounding_box_mse: nan\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5 # 45\n",
    "steps_per_epoch = trainTargets[\"bounding_box\"].shape[0]//BATCH_SIZE  # need number of training items only!\n",
    "validation_steps = 1\n",
    "\n",
    "history = model.fit(training_images, trainTargets,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=(test_images, testTargets),\n",
    "                    validation_steps=validation_steps, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate!\n",
    "loss, classification_loss, bounding_box_loss, classification_accuracy, bounding_box_mse = model.evaluate(test_images, testTargets, steps=1)\n",
    "print(\"Validation accuracy: \", classification_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "C3_W1_Lab_3_Object_Localization.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
